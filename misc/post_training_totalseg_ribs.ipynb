{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path \n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_wandb_run(anatomy,project_name='msrepo/2d-3d-benchmark',tags=['model-compare']):\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(project_name,filters={\n",
    "        'tags':{'$in':tags}\n",
    "    })\n",
    "    filtered_runs = [ run for run in runs if run.config['ANATOMY'] == anatomy]\n",
    "    return filtered_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_checkpoint(path):\n",
    "    checkpoints = list(Path(path).glob('epoch=*.ckpt'))\n",
    "    latest_checkpoint_path = max(checkpoints,key=lambda x: x.lstat().st_ctime)\n",
    "    return str(latest_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_name_from_model_name(model_name):\n",
    "    expt_dict = {'OneDConcat':'ParallelHeadsExperiment','MultiScale2DPermuteConcat':'ParallelHeadsExperiment','TwoDPermuteConcat':'ParallelHeadsExperiment','AttentionUnet':'VolumeAsInputExperiment',\n",
    "    'UNet':'VolumeAsInputExperiment'}\n",
    "    return expt_dict[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_from_model_name(model_name,wandb_runs):\n",
    "    for run in wandb_runs:\n",
    "        if run.config['MODEL_NAME'] == model_name:\n",
    "            return run\n",
    "    raise ValueError(f'{model_name} not found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = 'configs/paths/totalsegmentator_ribs/TotalSegmentor-ribs-DRR-full_train+val.csv'\n",
    "test_csv_path = 'configs/paths/totalsegmentator_ribs/TotalSegmentor-ribs-DRR-full_test.csv'\n",
    "gpu = 0\n",
    "rib_img_size = 128\n",
    "rib_resolution = 2.5\n",
    "rib_runs = filter_wandb_run(anatomy='ribs')\n",
    "for run in rib_runs:\n",
    "    model_name = run.config['MODEL_NAME']\n",
    "    input_type = get_experiment_name_from_model_name(model_name)\n",
    "    run_id = str(run.id)\n",
    "    checkpoint_path = get_latest_checkpoint(f'runs/2d-3d-benchmark/{run_id}/checkpoints/') \n",
    "    output_dir = f'runs/2d-3d-benchmark/{run_id}/evaluation'\n",
    "    command = f'python train.py  {train_csv_path} {test_csv_path} --gpu {gpu} --tags   model-compare --size {rib_img_size} --batch_size 8 --accelerator gpu --res {rib_resolution} --precision 16 --model_name {model_name} --experiment_name {input_type} --epochs -1 --anatomy ribs --loss DiceLoss  --lr 0.002 --steps 3000 --evaluate --save_predictions --checkpoint_path {checkpoint_path} --output_dir {output_dir}'\n",
    "    os.system(command)\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31nmkymw AttentionUnet\n",
      "r83x5x6c UNet\n",
      "iaqut884 MultiScale2DPermuteConcat\n",
      "7lmns8ui TwoDPermuteConcat\n",
      "4pmso51m OneDConcat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' & AttentionUnet &  & 0.52  & 4.48 & 1.23  & 0.52\\\\ & UNet &  & 0.46  & 4.76 & 1.35  & 0.47\\\\ & MultiScale2DPermuteConcat &  & 0.40  & 9.52 & 1.47  & 0.40\\\\ & TwoDPermuteConcat &  & 0.49  & 5.85 & 0.94  & 0.47\\\\ & OneDConcat &  & 0.28  & 16.88 & 2.62  & 0.28\\\\'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "latex_table = \"\"\n",
    "latex_table_row_template = \" & {model_name} &  & {DSC:.2f}  & {HD95:.2f} & {ASD:.2f}  & {NSD:.2f}\\\\\"\n",
    "MODEL_NAMES = ['AttentionUnet','UNet','MultiScale2DPermuteConcat','TwoDPermuteConcat','OneDConcat']\n",
    "for model in MODEL_NAMES:\n",
    "    run = get_run_from_model_name(model,rib_runs)\n",
    "    print(run.id,run.config['MODEL_NAME'])\n",
    "    eval_log_csv_path = f'/mnt/SSD0/mahesh-home/xrayto3D-benchmark/runs/2d-3d-benchmark/{run.id}/evaluation/metric-log.csv'\n",
    "    df = pd.read_csv(eval_log_csv_path)\n",
    "    latex_table += latex_table_row_template.format(\n",
    "        model_name=run.config['MODEL_NAME'],\n",
    "        DSC = df.mean(numeric_only=True).DSC,\n",
    "        HD95 = df.mean(numeric_only=True).HD95,\n",
    "        ASD = df.mean(numeric_only=True).ASD,\n",
    "        NSD = df.mean(numeric_only=True).NSD)\n",
    "latex_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xrayto3dbenchmark-cuda_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "662bdad93655923bdfd290e6298f1b08a08219358abebfe44fc131957365ec24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
